{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AlGegvYifLdD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "-mUM_cSThsZN",
    "outputId": "bb3d10e5-6408-44e6-e44f-c5d7cd644e5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.974998</td>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.087502</td>\n",
       "      <td>45.255402</td>\n",
       "      <td>6027072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>61.525002</td>\n",
       "      <td>62.924999</td>\n",
       "      <td>57.912498</td>\n",
       "      <td>58.299999</td>\n",
       "      <td>43.190327</td>\n",
       "      <td>5325328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.049999</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>59.012501</td>\n",
       "      <td>43.718178</td>\n",
       "      <td>4198040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-06</td>\n",
       "      <td>59.924999</td>\n",
       "      <td>60.187500</td>\n",
       "      <td>56.875000</td>\n",
       "      <td>57.262501</td>\n",
       "      <td>42.421741</td>\n",
       "      <td>4121520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>56.062500</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>41.930927</td>\n",
       "      <td>2650800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>3685.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>3644.800049</td>\n",
       "      <td>3670.899902</td>\n",
       "      <td>3664.460693</td>\n",
       "      <td>2209923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>3671.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3653.100098</td>\n",
       "      <td>3696.100098</td>\n",
       "      <td>3689.616699</td>\n",
       "      <td>1534135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>3710.000000</td>\n",
       "      <td>3725.000000</td>\n",
       "      <td>3693.850098</td>\n",
       "      <td>3706.550049</td>\n",
       "      <td>3700.048340</td>\n",
       "      <td>1456218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>3692.250000</td>\n",
       "      <td>3719.949951</td>\n",
       "      <td>3685.000000</td>\n",
       "      <td>3694.699951</td>\n",
       "      <td>3688.218994</td>\n",
       "      <td>1456923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>3681.350098</td>\n",
       "      <td>3740.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3733.750000</td>\n",
       "      <td>3727.200684</td>\n",
       "      <td>1966475.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4724 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Open         High          Low        Close  \\\n",
       "0     2003-01-01    59.987499    61.974998    59.987499    61.087502   \n",
       "1     2003-01-02    61.525002    62.924999    57.912498    58.299999   \n",
       "2     2003-01-03    60.000000    61.049999    58.500000    59.012501   \n",
       "3     2003-01-06    59.924999    60.187500    56.875000    57.262501   \n",
       "4     2003-01-07    58.000000    58.500000    56.062500    56.599998   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "4719  2021-12-24  3685.000000  3705.000000  3644.800049  3670.899902   \n",
       "4720  2021-12-27  3671.000000  3700.000000  3653.100098  3696.100098   \n",
       "4721  2021-12-28  3710.000000  3725.000000  3693.850098  3706.550049   \n",
       "4722  2021-12-29  3692.250000  3719.949951  3685.000000  3694.699951   \n",
       "4723  2021-12-30  3681.350098  3740.000000  3680.000000  3733.750000   \n",
       "\n",
       "        Adj Close     Volume  \n",
       "0       45.255402  6027072.0  \n",
       "1       43.190327  5325328.0  \n",
       "2       43.718178  4198040.0  \n",
       "3       42.421741  4121520.0  \n",
       "4       41.930927  2650800.0  \n",
       "...           ...        ...  \n",
       "4719  3664.460693  2209923.0  \n",
       "4720  3689.616699  1534135.0  \n",
       "4721  3700.048340  1456218.0  \n",
       "4722  3688.218994  1456923.0  \n",
       "4723  3727.200684  1966475.0  \n",
       "\n",
       "[4724 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TCS.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "AM-5iw8Zpv86",
    "outputId": "21005e0d-af28-49d2-f488-d7debeae81c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.087502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.012501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.262501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.599998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Close\n",
       "0  61.087502\n",
       "1  58.299999\n",
       "2  59.012501\n",
       "3  57.262501\n",
       "4  56.599998"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Close']]\n",
    "df.dropna(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gQSH_F5MrCTb"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EHf9S2S05MOp"
   },
   "outputs": [],
   "source": [
    "trainSize = int(len(data)*0.8)\n",
    "testSize = len(data) - trainSize\n",
    "train = data[0:trainSize]\n",
    "test = data[trainSize:len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTXLe5Vf5-yW",
    "outputId": "cd495460-c0af-4384-d46c-c57d00e3edc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4715, 1)\n",
      "(3772, 1)\n",
      "(943, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qnkLzVxh09VJ"
   },
   "outputs": [],
   "source": [
    "def modify(data, pastDays = 14):\n",
    "  X = []\n",
    "  Y = []\n",
    "  for i in range(pastDays, len(data)):\n",
    "      X.append(data[i - pastDays: i, 0: data.shape[1]])\n",
    "      Y.append(data[i : i + 1, 0])\n",
    "  return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SrCav3Wz6_s3"
   },
   "outputs": [],
   "source": [
    "trainX, trainY = modify(train)\n",
    "testX, testY = modify(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSlibsFOJE2d"
   },
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1rg19nVI-IW",
    "outputId": "bc1c72cb-1e10-408e-eaff-c7a51845e670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 14, 150)           22800     \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 14, 150)           45150     \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 150)               45150     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,251\n",
      "Trainable params: 113,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model1.add(SimpleRNN(150, return_sequences = True))\n",
    "model1.add(SimpleRNN(150, return_sequences = True))\n",
    "model1.add(SimpleRNN(150))\n",
    "model1.add(Dense(trainY.shape[1]))\n",
    "model1.compile(optimizer='adam', loss='mse')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzyIzyCeJMmQ",
    "outputId": "5eabc68c-a276-43ce-e7f6-7bdc34d18648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 5s 25ms/step - loss: 0.0720 - val_loss: 1.5704e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 4.5843e-05 - val_loss: 1.6273e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 4.2205e-05 - val_loss: 1.5780e-04\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 3.5917e-05 - val_loss: 1.1366e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 4.4693e-05 - val_loss: 1.1324e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 4.4124e-05 - val_loss: 2.0435e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 4.7158e-05 - val_loss: 2.4778e-04\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 6.0694e-05 - val_loss: 9.9766e-05\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 1.0355e-04 - val_loss: 3.4703e-04\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 7.4356e-05 - val_loss: 6.6727e-04\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 4.9575e-05 - val_loss: 8.3583e-05\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 9.8310e-05 - val_loss: 2.0006e-04\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 4.9833e-05 - val_loss: 1.1407e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 4.4769e-05 - val_loss: 2.5708e-04\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 7.4227e-05 - val_loss: 9.8597e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 9.8210e-05 - val_loss: 1.9279e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 1.5045e-04 - val_loss: 9.8915e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 4.5727e-05 - val_loss: 1.3649e-04\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 4.6913e-05 - val_loss: 8.9184e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 8.2608e-05 - val_loss: 1.3149e-04\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 4.3815e-05 - val_loss: 4.9909e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 5.7699e-05 - val_loss: 6.2086e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 1.1015e-04 - val_loss: 3.1114e-04\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 6.5100e-05 - val_loss: 9.0411e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 5.1808e-05 - val_loss: 7.4692e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 4.8903e-05 - val_loss: 4.9364e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 6.5654e-05 - val_loss: 4.4508e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 4.4759e-05 - val_loss: 1.8773e-04\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 6.6650e-05 - val_loss: 5.4360e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 5.4471e-05 - val_loss: 6.8589e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 4.0010e-05 - val_loss: 5.4949e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 2.7747e-05 - val_loss: 3.4459e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 4.0482e-05 - val_loss: 2.6097e-04\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 1.6793e-04 - val_loss: 5.7696e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 2.2959e-05 - val_loss: 3.6635e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 2.3308e-05 - val_loss: 6.9854e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 2.6676e-05 - val_loss: 4.0404e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 3.7482e-05 - val_loss: 3.0499e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 1.6638e-05 - val_loss: 2.9700e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 5.0108e-05 - val_loss: 3.4357e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 1.7952e-05 - val_loss: 3.3068e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 1.6990e-05 - val_loss: 2.8684e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 2.4173e-05 - val_loss: 2.7144e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 2.3913e-05 - val_loss: 4.4361e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 3.9617e-05 - val_loss: 2.9433e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 1.8644e-05 - val_loss: 5.2059e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 1.9776e-05 - val_loss: 6.4778e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 1.9108e-05 - val_loss: 5.6815e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 2.3922e-05 - val_loss: 7.6984e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 1.0849e-05 - val_loss: 3.8623e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22be867ae80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RNN(Uni)\\assets\n"
     ]
    }
   ],
   "source": [
    "model1.save('RNN(Uni)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HLNTNT3FqB1"
   },
   "source": [
    "Classic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrK6_RTR8Joj",
    "outputId": "88cb5e6f-fe5c-4b96-a842-c0ca8924ba96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 14, 150)           91200     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 14, 150)           180600    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 150)               180600    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 452,551\n",
      "Trainable params: 452,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model2.add(LSTM(150, return_sequences = True))\n",
    "model2.add(LSTM(150, return_sequences = True))\n",
    "model2.add(LSTM(150))\n",
    "model2.add(Dense(trainY.shape[1]))\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLCcQBiADlBw",
    "outputId": "3b15c5db-a311-41f7-d5c7-a7767f09e581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 12s 69ms/step - loss: 6.7417e-04 - val_loss: 1.2544e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 3.4924e-05 - val_loss: 1.3224e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 3.7684e-05 - val_loss: 2.4553e-04\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 4.8706e-05 - val_loss: 1.3207e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 4.0693e-05 - val_loss: 1.3885e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 3.5957e-05 - val_loss: 1.8580e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 4.1352e-05 - val_loss: 1.0371e-04\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 3.3140e-05 - val_loss: 1.2840e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 3.9449e-05 - val_loss: 1.4874e-04\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 3.6044e-05 - val_loss: 1.2943e-04\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 3.4215e-05 - val_loss: 1.1187e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 3.0449e-05 - val_loss: 1.1415e-04\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 4.7059e-05 - val_loss: 2.5624e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 6s 63ms/step - loss: 3.1107e-05 - val_loss: 1.0155e-04\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 2.8058e-05 - val_loss: 8.4081e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 2.9862e-05 - val_loss: 1.4538e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 3.5573e-05 - val_loss: 7.3173e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 2.6828e-05 - val_loss: 8.3220e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 6s 59ms/step - loss: 2.9809e-05 - val_loss: 7.1357e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 6s 66ms/step - loss: 2.3718e-05 - val_loss: 1.3057e-04\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 7s 72ms/step - loss: 2.8527e-05 - val_loss: 1.6668e-04\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 2.5231e-05 - val_loss: 2.3444e-04\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 2.3122e-05 - val_loss: 5.9251e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 2.5009e-05 - val_loss: 1.2428e-04\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 2.3885e-05 - val_loss: 7.4693e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 4s 48ms/step - loss: 3.4548e-05 - val_loss: 2.0638e-04\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 2.7513e-05 - val_loss: 5.1976e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 2.2105e-05 - val_loss: 1.2899e-04\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.8393e-05 - val_loss: 4.4960e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 1.8091e-05 - val_loss: 5.0813e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 1.7264e-05 - val_loss: 6.1140e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 1.4635e-05 - val_loss: 4.7469e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.3117e-05 - val_loss: 3.7166e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.8307e-05 - val_loss: 4.0603e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.6552e-05 - val_loss: 3.5159e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.3946e-05 - val_loss: 3.9614e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.3417e-05 - val_loss: 3.6039e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.2937e-05 - val_loss: 3.1854e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 6s 66ms/step - loss: 1.4337e-05 - val_loss: 4.4493e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 6s 59ms/step - loss: 1.5831e-05 - val_loss: 3.1142e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.2139e-05 - val_loss: 2.9369e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.1895e-05 - val_loss: 3.1042e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 5s 53ms/step - loss: 1.1761e-05 - val_loss: 3.0017e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 6s 67ms/step - loss: 1.3811e-05 - val_loss: 2.8672e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 1.8933e-05 - val_loss: 5.2387e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 4s 48ms/step - loss: 1.5515e-05 - val_loss: 2.6105e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 1.2149e-05 - val_loss: 2.7877e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 1.0318e-05 - val_loss: 2.6758e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 1.1163e-05 - val_loss: 4.7403e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.1049e-05 - val_loss: 2.4145e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22bebbbdf40>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EoZKsfkLXH5",
    "outputId": "9c52a328-d20f-49c2-ea57-7f8de64f244b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM(Uni)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM(Uni)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022BECDDC9A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022BEBCD4460> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022BE74C2E50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model2.save('LSTM(Uni)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf7GoafTMuF1"
   },
   "source": [
    "LSTM Peephole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMBfWAw7MmD6",
    "outputId": "4b918516-80c6-411d-ef17-9ea2ea396a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rnn (RNN)                   (None, 14, 150)           91650     \n",
      "                                                                 \n",
      " rnn_1 (RNN)                 (None, 14, 150)           181050    \n",
      "                                                                 \n",
      " rnn_2 (RNN)                 (None, 150)               181050    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 453,901\n",
      "Trainable params: 453,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model3.add(RNN(tfa.rnn.PeepholeLSTMCell(150), return_sequences = True))\n",
    "model3.add(RNN(tfa.rnn.PeepholeLSTMCell(150), return_sequences = True))\n",
    "model3.add(RNN(tfa.rnn.PeepholeLSTMCell(150)))\n",
    "model3.add(Dense(trainY.shape[1]))\n",
    "model3.compile(optimizer='adam', loss='mse')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imUyvlS2GRxs",
    "outputId": "ad0d6802-d9a2-4ac4-dbe3-1728dc63fc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 12s 68ms/step - loss: 6.2772e-04 - val_loss: 1.1594e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 3.4344e-05 - val_loss: 1.5662e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 4.3497e-05 - val_loss: 1.1775e-04\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 4s 48ms/step - loss: 4.4075e-05 - val_loss: 1.3527e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 4.1705e-05 - val_loss: 1.1544e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 6.2239e-05 - val_loss: 1.0244e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 5s 53ms/step - loss: 3.2944e-05 - val_loss: 1.2858e-04\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 6s 65ms/step - loss: 3.1856e-05 - val_loss: 1.1204e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 3.7187e-05 - val_loss: 2.3976e-04\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 5s 48ms/step - loss: 3.2250e-05 - val_loss: 9.7566e-05\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 3.2968e-05 - val_loss: 2.1888e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 3.7052e-05 - val_loss: 9.1079e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 6s 64ms/step - loss: 2.7399e-05 - val_loss: 1.5965e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 2.4093e-05 - val_loss: 8.6598e-05\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 3.3836e-05 - val_loss: 7.3857e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 4s 48ms/step - loss: 2.7737e-05 - val_loss: 8.1105e-05\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 4s 47ms/step - loss: 3.7589e-05 - val_loss: 7.4705e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 4s 48ms/step - loss: 2.8129e-05 - val_loss: 8.2272e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 2.2741e-05 - val_loss: 6.4551e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 2.1739e-05 - val_loss: 5.8104e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 6s 66ms/step - loss: 2.5541e-05 - val_loss: 5.5759e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 7s 74ms/step - loss: 2.6148e-05 - val_loss: 7.5789e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 6s 66ms/step - loss: 2.5734e-05 - val_loss: 5.5130e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 7s 69ms/step - loss: 1.8539e-05 - val_loss: 5.5445e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 6s 66ms/step - loss: 1.8050e-05 - val_loss: 1.0073e-04\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 6s 67ms/step - loss: 1.7562e-05 - val_loss: 4.4248e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 7s 72ms/step - loss: 2.2679e-05 - val_loss: 7.6215e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 7s 69ms/step - loss: 1.7749e-05 - val_loss: 5.6064e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 6s 65ms/step - loss: 1.4846e-05 - val_loss: 3.9635e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 1.5215e-05 - val_loss: 1.5882e-04\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 1.6489e-05 - val_loss: 9.8236e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 1.6228e-05 - val_loss: 4.0786e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 1.7825e-05 - val_loss: 3.5027e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 1.7176e-05 - val_loss: 4.2060e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 1.2472e-05 - val_loss: 3.7553e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.7452e-05 - val_loss: 7.5576e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 7s 80ms/step - loss: 1.6613e-05 - val_loss: 5.4020e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 6s 67ms/step - loss: 1.3903e-05 - val_loss: 2.8132e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 6s 63ms/step - loss: 1.1806e-05 - val_loss: 3.2190e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 5s 53ms/step - loss: 1.6901e-05 - val_loss: 3.3712e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 1.2750e-05 - val_loss: 3.2594e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 1.5670e-05 - val_loss: 5.4232e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 1.5290e-05 - val_loss: 4.5973e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 1.2163e-05 - val_loss: 2.5003e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 5s 53ms/step - loss: 1.2616e-05 - val_loss: 2.3178e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 1.2100e-05 - val_loss: 1.0349e-04\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 6s 64ms/step - loss: 1.2871e-05 - val_loss: 5.6126e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 7s 72ms/step - loss: 1.2644e-05 - val_loss: 6.5173e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 8s 80ms/step - loss: 1.1555e-05 - val_loss: 2.1532e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.0992e-05 - val_loss: 3.3940e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22bf8e86e80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nfnre6bLN2tC",
    "outputId": "52c68f08-1cc4-4d20-c480-be1a7c18b80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: PeepholeLSTM(Uni)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: PeepholeLSTM(Uni)\\assets\n",
      "WARNING:absl:<tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell object at 0x0000022BF7C81970> has the same name 'PeepholeLSTMCell' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell object at 0x0000022BF35CF220> has the same name 'PeepholeLSTMCell' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell object at 0x0000022BFB079C70> has the same name 'PeepholeLSTMCell' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model3.save('PeepholeLSTM(Uni)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SBjSIw1PC9l"
   },
   "source": [
    "Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rP8L8zroOwxu",
    "outputId": "fa6dfc5e-3314-4881-fac1-fec6d17397f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 14, 300)          182400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 14, 300)          541200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 300)              541200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,265,101\n",
      "Trainable params: 1,265,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model4.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model4.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model4.add(Bidirectional(LSTM(150)))\n",
    "model4.add(Dense(trainY.shape[1]))\n",
    "model4.compile(optimizer='adam', loss='mse')\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9CmgE-WPZ1X",
    "outputId": "0389a182-4faf-41ab-80ec-88f4cadea929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 48s 204ms/step - loss: 5.0032e-04 - val_loss: 1.0509e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 13s 141ms/step - loss: 3.6427e-05 - val_loss: 1.6621e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 18s 193ms/step - loss: 3.4405e-05 - val_loss: 9.3652e-05\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 23s 241ms/step - loss: 2.9404e-05 - val_loss: 8.8231e-05\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 21s 225ms/step - loss: 3.6602e-05 - val_loss: 9.2079e-05\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 2.8444e-05 - val_loss: 8.8572e-05\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 2.4864e-05 - val_loss: 8.0545e-05\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 22s 239ms/step - loss: 3.1180e-05 - val_loss: 9.7799e-05\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 2.5657e-05 - val_loss: 8.8914e-05\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 23s 242ms/step - loss: 2.1712e-05 - val_loss: 8.7583e-05\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 21s 228ms/step - loss: 3.0228e-05 - val_loss: 7.7294e-05\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 20s 217ms/step - loss: 3.7710e-05 - val_loss: 8.3557e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 20s 217ms/step - loss: 3.1356e-05 - val_loss: 6.1302e-05\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 21s 229ms/step - loss: 3.2010e-05 - val_loss: 9.5719e-05\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 22s 234ms/step - loss: 1.8316e-05 - val_loss: 5.3060e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 24s 252ms/step - loss: 1.9245e-05 - val_loss: 1.3534e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 22s 235ms/step - loss: 2.0348e-05 - val_loss: 1.3194e-04\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 21s 228ms/step - loss: 2.1686e-05 - val_loss: 4.7023e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 22s 237ms/step - loss: 1.7359e-05 - val_loss: 4.4423e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 24s 255ms/step - loss: 2.8177e-05 - val_loss: 1.7317e-04\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 23s 241ms/step - loss: 1.8792e-05 - val_loss: 4.7069e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 1.5135e-05 - val_loss: 1.1682e-04\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 2.6772e-05 - val_loss: 7.7124e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 23s 241ms/step - loss: 1.8209e-05 - val_loss: 4.2675e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 22s 238ms/step - loss: 1.6924e-05 - val_loss: 1.9894e-04\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 2.5982e-05 - val_loss: 5.1800e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 25s 266ms/step - loss: 1.7132e-05 - val_loss: 4.1709e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 16s 169ms/step - loss: 1.7694e-05 - val_loss: 4.5607e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 13s 139ms/step - loss: 1.5784e-05 - val_loss: 6.1639e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 13s 141ms/step - loss: 1.2185e-05 - val_loss: 4.1234e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 13s 138ms/step - loss: 1.3360e-05 - val_loss: 3.0536e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 13s 138ms/step - loss: 1.5359e-05 - val_loss: 3.0018e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 13s 134ms/step - loss: 1.6279e-05 - val_loss: 4.4077e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 14s 147ms/step - loss: 1.3454e-05 - val_loss: 7.5170e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 15s 161ms/step - loss: 1.7023e-05 - val_loss: 6.5821e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 15s 158ms/step - loss: 1.6515e-05 - val_loss: 2.4248e-04\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 14s 153ms/step - loss: 1.5780e-05 - val_loss: 3.5921e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 13s 142ms/step - loss: 1.5042e-05 - val_loss: 4.0450e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 13s 141ms/step - loss: 1.2073e-05 - val_loss: 2.7325e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 13s 139ms/step - loss: 1.5121e-05 - val_loss: 7.7372e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 13s 135ms/step - loss: 1.7976e-05 - val_loss: 4.6029e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 13s 136ms/step - loss: 1.3602e-05 - val_loss: 2.6672e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 13s 135ms/step - loss: 1.2481e-05 - val_loss: 3.2389e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 13s 134ms/step - loss: 1.4949e-05 - val_loss: 2.5186e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 13s 134ms/step - loss: 1.2475e-05 - val_loss: 2.8139e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 13s 135ms/step - loss: 1.1738e-05 - val_loss: 1.3847e-04\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 13s 143ms/step - loss: 1.1731e-05 - val_loss: 2.6761e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 14s 144ms/step - loss: 1.2176e-05 - val_loss: 5.6383e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 14s 144ms/step - loss: 1.3247e-05 - val_loss: 2.8982e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 13s 136ms/step - loss: 1.3145e-05 - val_loss: 7.6099e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22bffd4acd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gno_sGzuQojr",
    "outputId": "5b7d3a1c-e368-4d82-80c8-988183e85f35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiLSTM(Uni)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiLSTM(Uni)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022BF7C81070> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022BF56DE3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022B8CB8AAC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022BFFD7A520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022B8B798190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022BF9FD8790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model4.save('BiLSTM(Uni)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGRjqqezRIGZ"
   },
   "source": [
    "GRU(Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-Xn1YJzRHBc",
    "outputId": "39e50d8c-3a0e-4c5c-d26d-c6bd5c906942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 14, 150)           68850     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 14, 150)           135900    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 150)               135900    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 340,801\n",
      "Trainable params: 340,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model5.add(GRU(150, return_sequences = True))\n",
    "model5.add(GRU(150, return_sequences = True))\n",
    "model5.add(GRU(150))\n",
    "model5.add(Dense(trainY.shape[1]))\n",
    "model5.compile(optimizer='adam', loss='mse')\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bR9U9BJiRATb",
    "outputId": "fe81eb62-8114-4b60-9d80-14afab98f5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 48s 306ms/step - loss: 6.6225e-04 - val_loss: 5.7600e-05\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 10s 106ms/step - loss: 1.7115e-05 - val_loss: 9.1874e-05\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 10s 105ms/step - loss: 1.9385e-05 - val_loss: 6.7012e-05\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 10s 109ms/step - loss: 1.9051e-05 - val_loss: 5.3888e-05\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 10s 110ms/step - loss: 1.7282e-05 - val_loss: 6.5343e-05\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 11s 112ms/step - loss: 1.7989e-05 - val_loss: 1.2934e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 1.7287e-05 - val_loss: 4.6388e-05\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 12s 125ms/step - loss: 1.9827e-05 - val_loss: 1.2109e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 2.0317e-05 - val_loss: 5.0569e-05\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 1.8189e-05 - val_loss: 3.9841e-05\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 11s 119ms/step - loss: 1.4191e-05 - val_loss: 3.7634e-05\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 10s 108ms/step - loss: 1.6427e-05 - val_loss: 4.1528e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 10s 105ms/step - loss: 1.5315e-05 - val_loss: 5.0563e-05\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 10s 106ms/step - loss: 1.4271e-05 - val_loss: 9.1936e-05\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 11s 119ms/step - loss: 1.6949e-05 - val_loss: 6.6268e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 10s 104ms/step - loss: 1.5406e-05 - val_loss: 3.1272e-05\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 10s 107ms/step - loss: 1.6293e-05 - val_loss: 9.3520e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 10s 110ms/step - loss: 1.6112e-05 - val_loss: 2.8048e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 11s 112ms/step - loss: 1.4311e-05 - val_loss: 6.4918e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 10s 104ms/step - loss: 2.0120e-05 - val_loss: 4.2846e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 10s 109ms/step - loss: 1.1331e-05 - val_loss: 2.6468e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 1.3671e-05 - val_loss: 2.5495e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 1.1617e-05 - val_loss: 2.8712e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 10s 105ms/step - loss: 9.6880e-06 - val_loss: 2.4523e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 10s 108ms/step - loss: 1.4470e-05 - val_loss: 2.1526e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 10s 102ms/step - loss: 1.0624e-05 - val_loss: 2.3369e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 10s 106ms/step - loss: 1.0521e-05 - val_loss: 2.3396e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 10s 106ms/step - loss: 1.0785e-05 - val_loss: 3.5685e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 1.2565e-05 - val_loss: 3.0425e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 1.1046e-05 - val_loss: 2.4207e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 1.5800e-05 - val_loss: 1.0618e-04\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 10s 111ms/step - loss: 9.8741e-06 - val_loss: 1.9480e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 1.2059e-05 - val_loss: 1.9445e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 11s 118ms/step - loss: 1.2409e-05 - val_loss: 9.8236e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 11s 118ms/step - loss: 1.3031e-05 - val_loss: 5.3975e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 10s 105ms/step - loss: 1.6689e-05 - val_loss: 5.4781e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 10s 107ms/step - loss: 1.2495e-05 - val_loss: 2.7424e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 10s 108ms/step - loss: 1.5214e-05 - val_loss: 3.2576e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 10s 105ms/step - loss: 1.5028e-05 - val_loss: 3.3030e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 10s 105ms/step - loss: 1.2525e-05 - val_loss: 3.8237e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 1.1970e-05 - val_loss: 2.1680e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 11s 113ms/step - loss: 1.0606e-05 - val_loss: 3.9266e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 11s 111ms/step - loss: 1.1988e-05 - val_loss: 2.0718e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 12s 130ms/step - loss: 1.5421e-05 - val_loss: 3.0644e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 10s 106ms/step - loss: 1.2838e-05 - val_loss: 4.9204e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 13s 134ms/step - loss: 1.0728e-05 - val_loss: 8.4689e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 10s 102ms/step - loss: 1.3118e-05 - val_loss: 1.2973e-04\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 10s 107ms/step - loss: 1.2232e-05 - val_loss: 2.6436e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 10s 107ms/step - loss: 1.4580e-05 - val_loss: 2.2566e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 1.2123e-05 - val_loss: 2.4005e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b989ded60>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "kuyy4_n8Rz3v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GRU(Uni)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GRU(Uni)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022B9BE8EB50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022B9BE8E6D0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022BB52D98B0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model5.save('GRU(Uni)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_ykIJimTC14"
   },
   "source": [
    "Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLUfiJrPSc7y",
    "outputId": "d9e1ab91-1fc3-4642-fff4-48d7c3b4c456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 14, 300)          137700    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 14, 300)          406800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 300)              406800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 951,601\n",
      "Trainable params: 951,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model6.add(Bidirectional(GRU(150, return_sequences = True)))\n",
    "model6.add(Bidirectional(GRU(150, return_sequences = True)))\n",
    "model6.add(Bidirectional(GRU(150)))\n",
    "model6.add(Dense(trainY.shape[1]))\n",
    "model6.compile(optimizer='adam', loss='mse')\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iND_X8JNSkHe",
    "outputId": "fdefeb93-556b-43e8-9f1e-f6400f83bf93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 99s 204ms/step - loss: 3.7446e-04 - val_loss: 8.1190e-05\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 17s 176ms/step - loss: 2.2620e-05 - val_loss: 6.6592e-05\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 17s 179ms/step - loss: 2.2878e-05 - val_loss: 6.8621e-05\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 16s 168ms/step - loss: 2.0687e-05 - val_loss: 1.7325e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 15s 159ms/step - loss: 1.9434e-05 - val_loss: 1.3009e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 15s 161ms/step - loss: 1.6151e-05 - val_loss: 4.1687e-05\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 15s 163ms/step - loss: 1.5943e-05 - val_loss: 4.7104e-05\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 16s 165ms/step - loss: 1.5235e-05 - val_loss: 6.6582e-05\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 14s 154ms/step - loss: 1.7269e-05 - val_loss: 5.7375e-05\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 15s 157ms/step - loss: 1.5759e-05 - val_loss: 1.0149e-04\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 15s 158ms/step - loss: 1.4236e-05 - val_loss: 2.1576e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 16s 169ms/step - loss: 1.8238e-05 - val_loss: 3.6033e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 15s 159ms/step - loss: 1.4239e-05 - val_loss: 2.9507e-05\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 22s 231ms/step - loss: 1.4730e-05 - val_loss: 3.7893e-05\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 28s 294ms/step - loss: 4.4267e-05 - val_loss: 4.2449e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 29s 311ms/step - loss: 1.2228e-05 - val_loss: 2.9485e-05\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 27s 291ms/step - loss: 1.9668e-05 - val_loss: 2.8194e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 28s 299ms/step - loss: 1.7908e-05 - val_loss: 2.5622e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 28s 296ms/step - loss: 1.4840e-05 - val_loss: 2.5536e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 29s 311ms/step - loss: 1.4193e-05 - val_loss: 2.4687e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 26s 282ms/step - loss: 1.1715e-05 - val_loss: 2.9826e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 31s 329ms/step - loss: 1.3011e-05 - val_loss: 2.7432e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 29s 311ms/step - loss: 1.3475e-05 - val_loss: 4.0287e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 31s 330ms/step - loss: 1.2692e-05 - val_loss: 2.2285e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 30s 320ms/step - loss: 1.1661e-05 - val_loss: 4.7400e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 29s 306ms/step - loss: 1.2539e-05 - val_loss: 2.3502e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 30s 316ms/step - loss: 1.7555e-05 - val_loss: 3.7590e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 27s 293ms/step - loss: 1.3711e-05 - val_loss: 4.0833e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 17s 181ms/step - loss: 1.6150e-05 - val_loss: 3.7456e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 17s 180ms/step - loss: 1.1014e-05 - val_loss: 2.1873e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 17s 179ms/step - loss: 1.6583e-05 - val_loss: 2.2563e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 18s 196ms/step - loss: 1.8085e-05 - val_loss: 2.3357e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 17s 177ms/step - loss: 1.3967e-05 - val_loss: 7.0649e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 16s 175ms/step - loss: 1.1099e-05 - val_loss: 4.6536e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 16s 169ms/step - loss: 1.4165e-05 - val_loss: 2.5715e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 15s 158ms/step - loss: 1.1485e-05 - val_loss: 3.1931e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 14s 146ms/step - loss: 1.3899e-05 - val_loss: 2.7362e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 22s 235ms/step - loss: 1.2704e-05 - val_loss: 3.0529e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 20s 214ms/step - loss: 1.5551e-05 - val_loss: 3.8338e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 1.2619e-05 - val_loss: 8.0436e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 28s 295ms/step - loss: 1.2317e-05 - val_loss: 4.9545e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 26s 274ms/step - loss: 1.0599e-05 - val_loss: 2.3347e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 27s 284ms/step - loss: 1.1470e-05 - val_loss: 2.0735e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 26s 281ms/step - loss: 1.1098e-05 - val_loss: 5.6809e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 27s 287ms/step - loss: 1.2665e-05 - val_loss: 2.3032e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 26s 274ms/step - loss: 1.3678e-05 - val_loss: 2.0191e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 27s 285ms/step - loss: 9.8002e-06 - val_loss: 1.9360e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 25s 266ms/step - loss: 1.1561e-05 - val_loss: 2.3736e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 26s 274ms/step - loss: 1.7775e-05 - val_loss: 2.2667e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 23s 243ms/step - loss: 1.5836e-05 - val_loss: 1.9681e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22bb647dca0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwWI_Xky3TAW",
    "outputId": "7e6abb50-f7a9-435e-e080-b4dec8d02549"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiGRU(Uni)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiGRU(Uni)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022BAB284D30> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022BAB22F190> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022BAB3A2F10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022B988F8B50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022B99AEEFD0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022BFD31F760> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model6.save('BiGRU(Uni)')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "StockPricePrediction(univariate).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
