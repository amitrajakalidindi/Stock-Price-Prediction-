{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNG-nK7pcR-7"
   },
   "source": [
    "Stock price prediction using multivariate data(Open, High, Low, Close, Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AlGegvYifLdD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-mUM_cSThsZN",
    "outputId": "e7dd1f2d-20c0-4bce-c6b5-f075eac7d259"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.974998</td>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.087502</td>\n",
       "      <td>45.255402</td>\n",
       "      <td>6027072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>61.525002</td>\n",
       "      <td>62.924999</td>\n",
       "      <td>57.912498</td>\n",
       "      <td>58.299999</td>\n",
       "      <td>43.190327</td>\n",
       "      <td>5325328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.049999</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>59.012501</td>\n",
       "      <td>43.718178</td>\n",
       "      <td>4198040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-06</td>\n",
       "      <td>59.924999</td>\n",
       "      <td>60.187500</td>\n",
       "      <td>56.875000</td>\n",
       "      <td>57.262501</td>\n",
       "      <td>42.421741</td>\n",
       "      <td>4121520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>56.062500</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>41.930927</td>\n",
       "      <td>2650800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2003-01-01  59.987499  61.974998  59.987499  61.087502  45.255402   \n",
       "1  2003-01-02  61.525002  62.924999  57.912498  58.299999  43.190327   \n",
       "2  2003-01-03  60.000000  61.049999  58.500000  59.012501  43.718178   \n",
       "3  2003-01-06  59.924999  60.187500  56.875000  57.262501  42.421741   \n",
       "4  2003-01-07  58.000000  58.500000  56.062500  56.599998  41.930927   \n",
       "\n",
       "      Volume  \n",
       "0  6027072.0  \n",
       "1  5325328.0  \n",
       "2  4198040.0  \n",
       "3  4121520.0  \n",
       "4  2650800.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TCS.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Xvx1UV5Qh6C2",
    "outputId": "13aad46d-1a25-4699-9a78-190c151b54b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.974998</td>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.087502</td>\n",
       "      <td>6027072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>61.525002</td>\n",
       "      <td>62.924999</td>\n",
       "      <td>57.912498</td>\n",
       "      <td>58.299999</td>\n",
       "      <td>5325328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.049999</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>59.012501</td>\n",
       "      <td>4198040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-06</td>\n",
       "      <td>59.924999</td>\n",
       "      <td>60.187500</td>\n",
       "      <td>56.875000</td>\n",
       "      <td>57.262501</td>\n",
       "      <td>4121520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>56.062500</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>2650800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close     Volume\n",
       "0  2003-01-01  59.987499  61.974998  59.987499  61.087502  6027072.0\n",
       "1  2003-01-02  61.525002  62.924999  57.912498  58.299999  5325328.0\n",
       "2  2003-01-03  60.000000  61.049999  58.500000  59.012501  4198040.0\n",
       "3  2003-01-06  59.924999  60.187500  56.875000  57.262501  4121520.0\n",
       "4  2003-01-07  58.000000  58.500000  56.062500  56.599998  2650800.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "df.dropna(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "eu5sOQXhi8hH",
    "outputId": "216fb724-1eff-4e43-d62f-7c3ad3a7d6b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='Date', y='Close', kind='line', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AM-5iw8Zpv86",
    "outputId": "26ef9e38-2325-4a9e-ebde-67b9188809fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.974998</td>\n",
       "      <td>59.987499</td>\n",
       "      <td>61.087502</td>\n",
       "      <td>6027072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.525002</td>\n",
       "      <td>62.924999</td>\n",
       "      <td>57.912498</td>\n",
       "      <td>58.299999</td>\n",
       "      <td>5325328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.049999</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>59.012501</td>\n",
       "      <td>4198040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.924999</td>\n",
       "      <td>60.187500</td>\n",
       "      <td>56.875000</td>\n",
       "      <td>57.262501</td>\n",
       "      <td>4121520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>56.062500</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>2650800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High        Low      Close     Volume\n",
       "0  59.987499  61.974998  59.987499  61.087502  6027072.0\n",
       "1  61.525002  62.924999  57.912498  58.299999  5325328.0\n",
       "2  60.000000  61.049999  58.500000  59.012501  4198040.0\n",
       "3  59.924999  60.187500  56.875000  57.262501  4121520.0\n",
       "4  58.000000  58.500000  56.062500  56.599998  2650800.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = df.Date\n",
    "df.drop(['Date'], inplace = True, axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gQSH_F5MrCTb"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uG5IpU7e68ON",
    "outputId": "e1da5677-32ed-4c99-87d7-5f92cacfe352"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00579649],\n",
       "       [0.0050847 ],\n",
       "       [0.00526664],\n",
       "       ...,\n",
       "       [0.9366727 ],\n",
       "       [0.93364675],\n",
       "       [0.94361826]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit_transform(df[['Close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnItwygzWO5G",
    "outputId": "c9e641b2-2775-488f-f902-2084afa3a474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4715, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EHf9S2S05MOp"
   },
   "outputs": [],
   "source": [
    "trainSize = int(len(data)*0.8)\n",
    "testSize = len(data) - trainSize\n",
    "train = data[0:trainSize]\n",
    "test = data[trainSize:len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qnkLzVxh09VJ"
   },
   "outputs": [],
   "source": [
    "def modify(data, pastDays = 14):\n",
    "  X = []\n",
    "  Y = []\n",
    "  for i in range(pastDays, len(data)):\n",
    "      X.append(data[i - pastDays: i, 0: data.shape[1]])\n",
    "      Y.append(data[i : i + 1, 3])\n",
    "  return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SrCav3Wz6_s3"
   },
   "outputs": [],
   "source": [
    "trainX, trainY = modify(train)\n",
    "testX, testY = modify(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSlibsFOJE2d"
   },
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1rg19nVI-IW",
    "outputId": "36216240-5705-47cd-ac0a-1671f27e70a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 14, 150)           23400     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 14, 150)           45150     \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 150)               45150     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,851\n",
      "Trainable params: 113,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model1.add(SimpleRNN(150, return_sequences = True))\n",
    "model1.add(SimpleRNN(150, return_sequences = True))\n",
    "model1.add(SimpleRNN(150))\n",
    "model1.add(Dense(trainY.shape[1]))\n",
    "model1.compile(optimizer='adam', loss='mse')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzyIzyCeJMmQ",
    "outputId": "dec487fe-2257-4eb5-8493-a9ea1b29abfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 28s 78ms/step - loss: 0.0899 - val_loss: 1.8447e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 4s 39ms/step - loss: 1.8112e-04 - val_loss: 2.4131e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 3s 37ms/step - loss: 1.1671e-04 - val_loss: 2.5731e-04\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 4s 37ms/step - loss: 1.0918e-04 - val_loss: 1.5852e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 8.5864e-05 - val_loss: 2.3407e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 4s 38ms/step - loss: 7.4005e-05 - val_loss: 1.6872e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 8.5206e-05 - val_loss: 1.1218e-04\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 1.0055e-04 - val_loss: 1.2868e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 8.4473e-05 - val_loss: 9.2243e-05\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 7.2740e-05 - val_loss: 1.3270e-04\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 9.1237e-05 - val_loss: 2.8046e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 1.0058e-04 - val_loss: 1.8696e-04\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 1.8553e-04 - val_loss: 5.5848e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 7.8634e-05 - val_loss: 8.8623e-05\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 9.2850e-05 - val_loss: 9.1328e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 1.0034e-04 - val_loss: 7.6466e-05\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 9.0328e-05 - val_loss: 2.7347e-04\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 3.0319e-04 - val_loss: 9.6878e-04\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 1.9552e-04 - val_loss: 6.9341e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 1.6226e-04 - val_loss: 7.3878e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 1.9548e-04 - val_loss: 6.2976e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 8.8658e-05 - val_loss: 1.5755e-04\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 2.3001e-04 - val_loss: 9.2317e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 1.2352e-04 - val_loss: 6.3213e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 7.1424e-04 - val_loss: 0.0063\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 2.1349e-04 - val_loss: 6.9949e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 1.2799e-04 - val_loss: 3.3044e-04\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 9.5372e-05 - val_loss: 1.0331e-04\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 5.4646e-05 - val_loss: 1.8636e-04\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 1.2052e-04 - val_loss: 3.9620e-04\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 1.5356e-04 - val_loss: 1.5064e-04\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 3.0720e-04 - val_loss: 1.0787e-04\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 7.2461e-05 - val_loss: 2.2888e-04\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 8.0317e-05 - val_loss: 9.0576e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 5.4129e-05 - val_loss: 6.4816e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 8.4768e-05 - val_loss: 2.4230e-04\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 1.5084e-04 - val_loss: 8.5618e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 2s 23ms/step - loss: 4.9345e-05 - val_loss: 3.3253e-04\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 2s 23ms/step - loss: 1.3647e-04 - val_loss: 5.6334e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 9.9566e-05 - val_loss: 2.9044e-04\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 8.7236e-05 - val_loss: 2.5000e-04\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 7.2729e-05 - val_loss: 3.6685e-04\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 1.0940e-04 - val_loss: 9.5411e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 1.2058e-04 - val_loss: 8.3805e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 4.2166e-05 - val_loss: 1.1106e-04\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 1.6633e-04 - val_loss: 5.0773e-04\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 7.5768e-05 - val_loss: 1.4683e-04\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 2s 18ms/step - loss: 4.8706e-05 - val_loss: 3.6767e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 2.9173e-05 - val_loss: 5.6139e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 3.1867e-05 - val_loss: 7.8087e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216ee508c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMxITShKKY1m",
    "outputId": "420c10d8-167d-4afa-8ca1-de65cc395dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RNN(Multi)\\assets\n"
     ]
    }
   ],
   "source": [
    "model1.save('RNN(Multi)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HLNTNT3FqB1"
   },
   "source": [
    "Classic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrK6_RTR8Joj",
    "outputId": "ccdfa5ae-faa4-4989-feea-12bb4847dadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 14, 150)           93600     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 14, 150)           180600    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 150)               180600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 454,951\n",
      "Trainable params: 454,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model2.add(LSTM(150, return_sequences = True))\n",
    "model2.add(LSTM(150, return_sequences = True))\n",
    "model2.add(LSTM(150))\n",
    "model2.add(Dense(trainY.shape[1]))\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLCcQBiADlBw",
    "outputId": "597895e0-8e20-4009-d63e-e6154c792b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 45s 285ms/step - loss: 4.0968e-04 - val_loss: 1.2163e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 4.0103e-05 - val_loss: 2.3577e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 4.2301e-05 - val_loss: 1.3051e-04\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 4.0696e-05 - val_loss: 2.2979e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 10s 112ms/step - loss: 4.5898e-05 - val_loss: 2.0262e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 11s 113ms/step - loss: 3.9595e-05 - val_loss: 1.2419e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 4.4577e-05 - val_loss: 1.0700e-04\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 10s 111ms/step - loss: 4.6249e-05 - val_loss: 1.0653e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 10s 111ms/step - loss: 3.3574e-05 - val_loss: 9.3404e-05\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 10s 110ms/step - loss: 3.2204e-05 - val_loss: 1.0414e-04\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 12s 125ms/step - loss: 4.3224e-05 - val_loss: 2.9309e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 3.6293e-05 - val_loss: 8.4482e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 3.0503e-05 - val_loss: 2.8907e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 3.7150e-05 - val_loss: 7.9137e-05\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 12s 124ms/step - loss: 3.0874e-05 - val_loss: 7.5049e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 11s 118ms/step - loss: 2.7919e-05 - val_loss: 2.4766e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 12s 126ms/step - loss: 2.8907e-05 - val_loss: 7.0474e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 11s 113ms/step - loss: 2.1616e-05 - val_loss: 1.1608e-04\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 3.1637e-05 - val_loss: 8.0480e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 10s 110ms/step - loss: 2.6781e-05 - val_loss: 7.3365e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 2.7966e-05 - val_loss: 6.7046e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 11s 118ms/step - loss: 2.1092e-05 - val_loss: 1.2795e-04\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 11s 119ms/step - loss: 1.9861e-05 - val_loss: 5.6696e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 1.8042e-05 - val_loss: 5.3094e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 11s 121ms/step - loss: 2.2937e-05 - val_loss: 9.6182e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 12s 124ms/step - loss: 2.1336e-05 - val_loss: 2.1799e-04\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 12s 127ms/step - loss: 2.2237e-05 - val_loss: 5.5689e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 11s 122ms/step - loss: 1.7909e-05 - val_loss: 8.7735e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 12s 124ms/step - loss: 1.4364e-05 - val_loss: 7.1710e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 11s 119ms/step - loss: 1.6737e-05 - val_loss: 1.7078e-04\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 11s 122ms/step - loss: 2.0201e-05 - val_loss: 3.8944e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 11s 119ms/step - loss: 1.4614e-05 - val_loss: 8.7143e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 12s 124ms/step - loss: 1.8470e-05 - val_loss: 5.6161e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 11s 122ms/step - loss: 1.6180e-05 - val_loss: 1.3146e-04\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 12s 129ms/step - loss: 1.3485e-05 - val_loss: 5.7303e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 11s 118ms/step - loss: 1.4666e-05 - val_loss: 8.6724e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 12s 122ms/step - loss: 1.4102e-05 - val_loss: 1.3030e-04\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 11s 120ms/step - loss: 1.3880e-05 - val_loss: 3.0331e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 11s 121ms/step - loss: 1.3694e-05 - val_loss: 4.5380e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 11s 120ms/step - loss: 1.2539e-05 - val_loss: 2.8253e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 12s 124ms/step - loss: 1.2843e-05 - val_loss: 3.7763e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 1.1746e-05 - val_loss: 4.1281e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 12s 127ms/step - loss: 1.4015e-05 - val_loss: 8.5410e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 11s 113ms/step - loss: 1.0363e-05 - val_loss: 2.4443e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 1.4502e-05 - val_loss: 2.5407e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 12s 124ms/step - loss: 1.5583e-05 - val_loss: 2.6347e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 12s 127ms/step - loss: 1.3842e-05 - val_loss: 3.7039e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 11s 120ms/step - loss: 1.2191e-05 - val_loss: 7.2189e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 12s 132ms/step - loss: 1.5475e-05 - val_loss: 3.2419e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 12s 125ms/step - loss: 9.0846e-06 - val_loss: 2.4245e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216f2b99820>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EoZKsfkLXH5",
    "outputId": "9738044a-c2b5-4d8a-e2b2-ac5dd854a814"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM(Multi)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM(Multi)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000216F3E13190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000216F3DD44F0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000216ED444AF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model2.save('LSTM(Multi)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf7GoafTMuF1"
   },
   "source": [
    "LSTM Peephole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMBfWAw7MmD6",
    "outputId": "e5a3c30d-1613-46c4-9699-1a22e7696a46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rnn (RNN)                   (None, 14, 150)           94050     \n",
      "                                                                 \n",
      " rnn_1 (RNN)                 (None, 14, 150)           181050    \n",
      "                                                                 \n",
      " rnn_2 (RNN)                 (None, 150)               181050    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 456,301\n",
      "Trainable params: 456,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model3.add(RNN(tfa.rnn.PeepholeLSTMCell(150), return_sequences = True))\n",
    "model3.add(RNN(tfa.rnn.PeepholeLSTMCell(150), return_sequences = True))\n",
    "model3.add(RNN(tfa.rnn.PeepholeLSTMCell(150)))\n",
    "model3.add(Dense(trainY.shape[1]))\n",
    "model3.compile(optimizer='adam', loss='mse')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "imUyvlS2GRxs",
    "outputId": "47e851f2-5380-4fec-c6e6-b26259239d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 92s 60ms/step - loss: 5.8774e-04 - val_loss: 1.6870e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 3.1932e-05 - val_loss: 1.1204e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 3.2681e-05 - val_loss: 1.5235e-04\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 3.6359e-05 - val_loss: 1.1956e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 3.7383e-05 - val_loss: 1.0353e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 4.0393e-05 - val_loss: 3.8017e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 5.0702e-05 - val_loss: 1.0703e-04\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 3.0056e-05 - val_loss: 1.4862e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 4.0830e-05 - val_loss: 1.0226e-04\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 3.2238e-05 - val_loss: 9.0536e-05\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 6s 59ms/step - loss: 3.8045e-05 - val_loss: 1.1725e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 3.1507e-05 - val_loss: 9.2307e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 3.1863e-05 - val_loss: 3.0528e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 6s 66ms/step - loss: 2.7607e-05 - val_loss: 1.3358e-04\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 7s 71ms/step - loss: 3.0249e-05 - val_loss: 9.7165e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 2.4647e-05 - val_loss: 1.4821e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 2.4997e-05 - val_loss: 8.6569e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 2.5360e-05 - val_loss: 8.1799e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 2.3057e-05 - val_loss: 7.7004e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 2.1697e-05 - val_loss: 7.0169e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 2.8936e-05 - val_loss: 6.1772e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 2.0622e-05 - val_loss: 6.4800e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 1.9536e-05 - val_loss: 1.6746e-04\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 5s 52ms/step - loss: 2.0167e-05 - val_loss: 7.8921e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 1.7807e-05 - val_loss: 6.3215e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 2.2357e-05 - val_loss: 5.9597e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 2.0072e-05 - val_loss: 1.4435e-04\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 1.6498e-05 - val_loss: 9.5454e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 2.1490e-05 - val_loss: 1.4838e-04\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 2.3796e-05 - val_loss: 4.2175e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 1.9328e-05 - val_loss: 5.7768e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 1.4516e-05 - val_loss: 5.0549e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 1.6292e-05 - val_loss: 3.7359e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 1.6750e-05 - val_loss: 3.8034e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.7834e-05 - val_loss: 5.4193e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.8123e-05 - val_loss: 7.8029e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.4992e-05 - val_loss: 5.4580e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 5s 48ms/step - loss: 1.3117e-05 - val_loss: 3.4539e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.3068e-05 - val_loss: 3.1556e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.2742e-05 - val_loss: 3.1615e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 5s 50ms/step - loss: 1.5364e-05 - val_loss: 3.6456e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.5791e-05 - val_loss: 1.9018e-04\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 5s 48ms/step - loss: 1.4236e-05 - val_loss: 2.7785e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 5s 48ms/step - loss: 1.0626e-05 - val_loss: 2.6868e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.2971e-05 - val_loss: 6.8618e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.4944e-05 - val_loss: 2.6460e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.3737e-05 - val_loss: 7.7771e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.2815e-05 - val_loss: 2.4641e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 5s 48ms/step - loss: 1.0519e-05 - val_loss: 2.3768e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 5s 48ms/step - loss: 1.0321e-05 - val_loss: 6.4302e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21680fdb040>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Nfnre6bLN2tC",
    "outputId": "2d6e642e-057e-49da-d2f8-c6b8c90af342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: PeepholeLSTM(Multi)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: PeepholeLSTM(Multi)\\assets\n",
      "WARNING:absl:<tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell object at 0x00000216FED580D0> has the same name 'PeepholeLSTMCell' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell object at 0x00000216820CDA00> has the same name 'PeepholeLSTMCell' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell object at 0x0000021682125A00> has the same name 'PeepholeLSTMCell' as a built-in Keras object. Consider renaming <class 'tensorflow_addons.rnn.peephole_lstm_cell.PeepholeLSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model3.save('PeepholeLSTM(Multi)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SBjSIw1PC9l"
   },
   "source": [
    "Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rP8L8zroOwxu",
    "outputId": "55461705-cb6b-4b9c-c140-0d4b812194e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 14, 300)          187200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 14, 300)          541200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 300)              541200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,269,901\n",
      "Trainable params: 1,269,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model4.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model4.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model4.add(Bidirectional(LSTM(150)))\n",
    "model4.add(Dense(trainY.shape[1]))\n",
    "model4.compile(optimizer='adam', loss='mse')\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "y9CmgE-WPZ1X",
    "outputId": "667b7654-f1c9-437b-8343-05d6fc31baad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 27s 165ms/step - loss: 6.0781e-04 - val_loss: 1.0449e-04\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 16s 169ms/step - loss: 2.9098e-05 - val_loss: 1.0418e-04\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 13s 139ms/step - loss: 3.2437e-05 - val_loss: 1.9224e-04\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 20s 211ms/step - loss: 2.7483e-05 - val_loss: 1.2665e-04\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 2.9772e-05 - val_loss: 3.4820e-04\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 22s 234ms/step - loss: 3.1548e-05 - val_loss: 1.3620e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 24s 259ms/step - loss: 2.7065e-05 - val_loss: 8.6151e-05\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 24s 255ms/step - loss: 3.6790e-05 - val_loss: 3.3938e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 21s 227ms/step - loss: 3.1150e-05 - val_loss: 1.0191e-04\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 22s 239ms/step - loss: 2.7020e-05 - val_loss: 7.0124e-05\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 20s 217ms/step - loss: 4.2773e-05 - val_loss: 1.3920e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 3.9775e-05 - val_loss: 8.5078e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 21s 225ms/step - loss: 2.5937e-05 - val_loss: 1.4802e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 22s 232ms/step - loss: 2.7614e-05 - val_loss: 6.1590e-05\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 20s 213ms/step - loss: 2.5829e-05 - val_loss: 9.6649e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 21s 225ms/step - loss: 2.3755e-05 - val_loss: 2.1444e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 23s 241ms/step - loss: 1.9266e-05 - val_loss: 1.0400e-04\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 2.1888e-05 - val_loss: 5.1615e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 22s 230ms/step - loss: 1.7410e-05 - val_loss: 6.1612e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 22s 233ms/step - loss: 2.5183e-05 - val_loss: 5.1083e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 20s 213ms/step - loss: 1.6873e-05 - val_loss: 6.0311e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 22s 230ms/step - loss: 1.9850e-05 - val_loss: 5.5130e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 2.2867e-05 - val_loss: 7.6734e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 22s 238ms/step - loss: 2.4584e-05 - val_loss: 6.8379e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 23s 241ms/step - loss: 1.6796e-05 - val_loss: 1.7745e-04\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 2.5721e-05 - val_loss: 2.0073e-04\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 20s 208ms/step - loss: 1.6298e-05 - val_loss: 5.4756e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 13s 137ms/step - loss: 1.6123e-05 - val_loss: 6.4963e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 13s 137ms/step - loss: 1.5438e-05 - val_loss: 4.1093e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 2.3274e-05 - val_loss: 9.7212e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 13s 143ms/step - loss: 1.8611e-05 - val_loss: 4.4976e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 13s 139ms/step - loss: 1.3467e-05 - val_loss: 3.7727e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 13s 141ms/step - loss: 1.5845e-05 - val_loss: 6.2319e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 14s 154ms/step - loss: 3.1989e-05 - val_loss: 3.6023e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 13s 138ms/step - loss: 1.4342e-05 - val_loss: 3.6979e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 14s 144ms/step - loss: 1.1988e-05 - val_loss: 3.2717e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 14s 145ms/step - loss: 1.2012e-05 - val_loss: 9.4118e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 14s 145ms/step - loss: 1.7057e-05 - val_loss: 3.5642e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 13s 136ms/step - loss: 1.3095e-05 - val_loss: 7.8400e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 14s 148ms/step - loss: 1.3104e-05 - val_loss: 9.2687e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 13s 141ms/step - loss: 1.4583e-05 - val_loss: 1.3881e-04\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 13s 140ms/step - loss: 1.9858e-05 - val_loss: 3.8239e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 13s 136ms/step - loss: 2.0904e-05 - val_loss: 3.4944e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 15s 157ms/step - loss: 1.3125e-05 - val_loss: 6.4038e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 14s 145ms/step - loss: 1.4460e-05 - val_loss: 6.2328e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 13s 135ms/step - loss: 1.5130e-05 - val_loss: 3.6104e-04\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 13s 140ms/step - loss: 1.6834e-05 - val_loss: 5.7851e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 15s 158ms/step - loss: 1.2226e-05 - val_loss: 2.8375e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 13s 141ms/step - loss: 1.2279e-05 - val_loss: 3.0127e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 17s 179ms/step - loss: 1.2336e-05 - val_loss: 6.4311e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216fda3df10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gno_sGzuQojr",
    "outputId": "18d07c94-8534-4a45-9bc3-fb5cba90c56a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiLSTM(Multi)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiLSTM(Multi)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021693DF5FA0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021693E15D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021693A21C70> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021693D24F70> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021688A18460> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000216F2B518B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model4.save('BiLSTM(Multi)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGRjqqezRIGZ"
   },
   "source": [
    "GRU(Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "F-Xn1YJzRHBc",
    "outputId": "bc400e49-8b26-4be7-dc1c-5dc326628170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 14, 150)           70650     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 14, 150)           135900    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 150)               135900    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 342,601\n",
      "Trainable params: 342,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model5.add(GRU(150, return_sequences = True))\n",
    "model5.add(GRU(150, return_sequences = True))\n",
    "model5.add(GRU(150))\n",
    "model5.add(Dense(trainY.shape[1]))\n",
    "model5.compile(optimizer='adam', loss='mse')\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bR9U9BJiRATb",
    "outputId": "b1b90e14-d5ed-4f84-842e-939dfc92c405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 47s 168ms/step - loss: 6.0377e-04 - val_loss: 6.3633e-05\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.7718e-05 - val_loss: 5.8972e-05\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 9s 95ms/step - loss: 2.0313e-05 - val_loss: 7.0562e-05\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 8s 83ms/step - loss: 1.7492e-05 - val_loss: 5.8666e-05\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.7801e-05 - val_loss: 5.3576e-05\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 9s 95ms/step - loss: 1.7288e-05 - val_loss: 1.2449e-04\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 8s 83ms/step - loss: 1.8465e-05 - val_loss: 2.9311e-04\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 10s 102ms/step - loss: 1.9254e-05 - val_loss: 1.1283e-04\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 8s 80ms/step - loss: 1.9189e-05 - val_loss: 6.1790e-05\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 7s 78ms/step - loss: 2.3256e-05 - val_loss: 4.8346e-05\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 9s 99ms/step - loss: 2.0346e-05 - val_loss: 1.5293e-04\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 8s 84ms/step - loss: 1.6860e-05 - val_loss: 4.0978e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 9s 94ms/step - loss: 2.2108e-05 - val_loss: 1.0604e-04\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.7239e-05 - val_loss: 1.1594e-04\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.4937e-05 - val_loss: 4.5754e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 7s 76ms/step - loss: 1.3894e-05 - val_loss: 1.4327e-04\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 9s 93ms/step - loss: 1.7108e-05 - val_loss: 6.7384e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.9351e-05 - val_loss: 3.4765e-05\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 2.2971e-05 - val_loss: 3.1585e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 8s 83ms/step - loss: 1.3035e-05 - val_loss: 4.4223e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.3812e-05 - val_loss: 3.9182e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 9s 98ms/step - loss: 1.2161e-05 - val_loss: 4.9962e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 8s 84ms/step - loss: 1.5718e-05 - val_loss: 8.5171e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 7s 75ms/step - loss: 1.2928e-05 - val_loss: 3.0536e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 8s 84ms/step - loss: 1.4520e-05 - val_loss: 4.5342e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 8s 89ms/step - loss: 1.7697e-05 - val_loss: 4.0368e-05\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 10s 105ms/step - loss: 1.4429e-05 - val_loss: 5.7362e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 9s 93ms/step - loss: 1.6106e-05 - val_loss: 7.2319e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 9s 95ms/step - loss: 1.3664e-05 - val_loss: 8.5533e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 8s 88ms/step - loss: 1.0880e-05 - val_loss: 2.7139e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 8s 83ms/step - loss: 1.3343e-05 - val_loss: 4.0126e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.1583e-05 - val_loss: 2.9993e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 8s 89ms/step - loss: 1.0919e-05 - val_loss: 2.1414e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 8s 90ms/step - loss: 2.0056e-05 - val_loss: 2.6340e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 9s 96ms/step - loss: 1.1206e-05 - val_loss: 4.6012e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 10s 102ms/step - loss: 1.0281e-05 - val_loss: 2.8015e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 8s 90ms/step - loss: 1.0259e-05 - val_loss: 3.1980e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 9s 91ms/step - loss: 1.9451e-05 - val_loss: 2.1454e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 9s 93ms/step - loss: 1.4930e-05 - val_loss: 6.8604e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 8s 87ms/step - loss: 1.2747e-05 - val_loss: 3.7876e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 9s 95ms/step - loss: 1.4285e-05 - val_loss: 2.8687e-05\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 9s 92ms/step - loss: 1.2152e-05 - val_loss: 2.5787e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.0141e-05 - val_loss: 2.0130e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 7s 78ms/step - loss: 1.1042e-05 - val_loss: 2.1496e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 9s 93ms/step - loss: 9.4846e-06 - val_loss: 2.0138e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 8s 89ms/step - loss: 1.0503e-05 - val_loss: 5.7907e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 9s 96ms/step - loss: 1.1630e-05 - val_loss: 2.0861e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 8s 88ms/step - loss: 1.2911e-05 - val_loss: 8.7924e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 9s 91ms/step - loss: 1.3275e-05 - val_loss: 2.2118e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.2075e-05 - val_loss: 3.9066e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216971c59d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kuyy4_n8Rz3v",
    "outputId": "19d316c2-975b-4455-e880-1e4d148a2791"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GRU(Multi)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GRU(Multi)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000002169721BF40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000216A0AFCA60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000021689D9CDC0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model5.save('GRU(Multi)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHQBZ2-4RmaF"
   },
   "source": [
    "Bidirection GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1dcyJDkgRh7A",
    "outputId": "0706e99b-393f-4f40-86af-f8b286e6056c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 14, 300)          141300    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 14, 300)          406800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 300)              406800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 955,201\n",
      "Trainable params: 955,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(InputLayer((trainX.shape[1], trainX.shape[2])))\n",
    "model6.add(Bidirectional(GRU(150, return_sequences = True)))\n",
    "model6.add(Bidirectional(GRU(150, return_sequences = True)))\n",
    "model6.add(Bidirectional(GRU(150)))\n",
    "model6.add(Dense(trainY.shape[1]))\n",
    "model6.compile(optimizer='adam', loss='mse')\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XrRHeDtFRxz5",
    "outputId": "51a5681b-b580-4b49-ced0-dac29d924557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 110s 512ms/step - loss: 5.4413e-04 - val_loss: 9.8029e-05\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 38s 400ms/step - loss: 2.3355e-05 - val_loss: 7.0942e-05\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 36s 387ms/step - loss: 2.0924e-05 - val_loss: 5.8044e-05\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 38s 405ms/step - loss: 1.9492e-05 - val_loss: 6.5174e-05\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 37s 397ms/step - loss: 1.9480e-05 - val_loss: 4.8930e-05\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 37s 395ms/step - loss: 1.8342e-05 - val_loss: 4.3398e-05\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 36s 387ms/step - loss: 1.7957e-05 - val_loss: 4.6739e-05\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 35s 376ms/step - loss: 1.7138e-05 - val_loss: 4.9224e-05\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 25s 265ms/step - loss: 1.8198e-05 - val_loss: 8.7118e-05\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 21s 226ms/step - loss: 2.6002e-05 - val_loss: 4.1449e-05\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 22s 230ms/step - loss: 1.7675e-05 - val_loss: 6.4463e-05\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 22s 233ms/step - loss: 1.5502e-05 - val_loss: 3.5129e-05\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 23s 249ms/step - loss: 1.4789e-05 - val_loss: 3.3064e-05\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 2.2038e-05 - val_loss: 2.4330e-04\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 19s 199ms/step - loss: 1.9505e-05 - val_loss: 3.1858e-05\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 18s 190ms/step - loss: 1.6502e-05 - val_loss: 5.5340e-05\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 16s 176ms/step - loss: 1.1818e-05 - val_loss: 3.2938e-05\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 19s 200ms/step - loss: 1.6215e-05 - val_loss: 1.3004e-04\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 17s 184ms/step - loss: 2.0094e-05 - val_loss: 2.9646e-05\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 17s 181ms/step - loss: 1.3058e-05 - val_loss: 2.8793e-05\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 19s 202ms/step - loss: 2.0788e-05 - val_loss: 3.6495e-05\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 18s 195ms/step - loss: 1.7242e-05 - val_loss: 2.6904e-05\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 18s 189ms/step - loss: 1.4040e-05 - val_loss: 2.6971e-05\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 17s 182ms/step - loss: 1.1121e-05 - val_loss: 2.6210e-05\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 20s 209ms/step - loss: 1.2942e-05 - val_loss: 3.2306e-05\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 24s 254ms/step - loss: 1.2270e-05 - val_loss: 1.3018e-04\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 17s 183ms/step - loss: 1.5739e-05 - val_loss: 7.2776e-05\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 16s 175ms/step - loss: 1.2868e-05 - val_loss: 7.4367e-05\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 17s 176ms/step - loss: 1.5408e-05 - val_loss: 2.3504e-05\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 16s 171ms/step - loss: 1.1950e-05 - val_loss: 3.7726e-05\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 1.3941e-05 - val_loss: 5.9252e-05\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 1.5885e-05 - val_loss: 3.6012e-05\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 1.2903e-05 - val_loss: 2.1880e-05\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 16s 175ms/step - loss: 1.5242e-05 - val_loss: 3.7807e-05\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 1.5629e-05 - val_loss: 4.2476e-05\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 1.1562e-05 - val_loss: 2.5541e-05\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 1.2260e-05 - val_loss: 2.4234e-05\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 1.8312e-05 - val_loss: 9.8751e-05\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 16s 173ms/step - loss: 1.2524e-05 - val_loss: 5.0551e-05\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 16s 173ms/step - loss: 1.3636e-05 - val_loss: 3.8112e-05\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 16s 174ms/step - loss: 1.3044e-05 - val_loss: 1.0040e-04\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 17s 176ms/step - loss: 1.6020e-05 - val_loss: 2.6648e-05\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 17s 185ms/step - loss: 1.1048e-05 - val_loss: 2.0100e-05\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 16s 175ms/step - loss: 1.1685e-05 - val_loss: 2.0666e-05\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 19s 207ms/step - loss: 1.0948e-05 - val_loss: 7.8734e-05\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 1.4290e-05 - val_loss: 2.1920e-05\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 19s 204ms/step - loss: 1.1563e-05 - val_loss: 2.0735e-05\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 20s 215ms/step - loss: 1.2350e-05 - val_loss: 2.1386e-05\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 18s 194ms/step - loss: 2.3416e-05 - val_loss: 5.6669e-05\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 18s 195ms/step - loss: 1.2872e-05 - val_loss: 8.4632e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216c4ed14f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(trainX, trainY, validation_split = 0.2, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6aeee7dgSI7i",
    "outputId": "c0be4783-5b7a-499d-e76b-fd0e73631f54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiGRU(Multi)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BiGRU(Multi)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000217002812B0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000216C4F20EE0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000216A83C1400> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000216B4451EB0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000216A50F3F40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000216B324F190> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model6.save('BiGRU(Multi)')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "StockPricePrediction(multivariate).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
